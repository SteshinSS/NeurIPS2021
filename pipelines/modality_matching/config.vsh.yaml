functionality:
  name: khrameeva_lab_submission
  namespace: match_modality_starter_kits
  
  # metadata for your method
  version: dev
  description: A description for your method.
  authors:
    - name: Simon Steshin
      email: SteshinSimon@gmail.com
      roles: [ author, maintainer ]
      props: { github: SteshinSS, orcid: "0000-1111-2222-3333" }
    - name: Alina Paronyan
      email: Alina.Paronyan@skoltech.ru
      roles: [ author, maintainer ]
      props: { github: alinaparonyan }
      
  # parameters
  arguments:
    # required inputs
    - name: "--input_train_mod1"
      type: "file"
      example: "dataset_censored.h5ad"
      description: "The censored shuffled train mod1 profiles."
      required: true
    - name: "--input_train_mod2"
      type: "file"
      example: "dataset_censored.h5ad"
      description: "The censored shuffled train mod2 profiles."
      required: true
    - name: "--input_train_sol"
      type: "file"
      example: "dataset_solution.h5ad"
      description: "The pairing of train mod1&mod2 profiles."
      required: true
    - name: "--input_test_mod1"
      type: "file"
      example: "dataset_censored.h5ad"
      description: "The censored shuffled test mod1 profiles."
      required: true
    - name: "--input_test_mod2"
      type: "file"
      example: "dataset_censored.h5ad"
      description: "The censored shuffled test mod2 profiles."
      required: true
    # required outputs
    - name: "--output"
      type: "file"
      direction: "output"
      example: "output.h5ad"
      description: "The predicted pairing of test mod1&mod2 profiles."
      required: true
      
  # files your script needs
  resources:
    - type: python_script
      path: script.py
    - type: file
      path: ../../lab_scripts
    - type: file
      path: ../../configs
    - type: file
      path: ../../checkpoints
  
  # resources for unit testing your component
  tests:
    - type: python_script
      path: test.py
    - path: sample_data

# target platforms
platforms:

  # By specifying 'docker' platform, viash will build a standalone
  # executable which uses docker in the back end to run your method.
  - type: docker
    # you need to specify a base image that contains at least bash and python
    image: pytorch/pytorch:1.9.0-cuda11.1-cudnn8-runtime
    run_args: [ "--gpus all"]
    # You can specify additional dependencies with 'setup'. 
    # See https://viash.io/docs/reference_config/platform-docker/#setup-list
    # for more information on how to add more dependencies.
    setup:
      # - type: apt
      #   packages:
      #     - bash
      # - type: python
      #   packages:
      #     - scanpy
      - type: python
        packages:
          - scikit-learn
          - anndata
          - scanpy
          - pyyaml
          - torch
          - pytorch-lightning
          - plotly


  # By specifying a 'nextflow', viash will also build a viash module
  # which uses the docker container built above to also be able to 
  # run your method as part of a nextflow pipeline.
  - type: nextflow
    labels: [ midmem, hightime, highcpu, gpu  ]
