{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Modality Prediction Baseline on NeuralNets\n",
    "Brings AI"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "\n",
    "from lab_scripts.data import dataloader\n",
    "from lab_scripts.models.baselines import neuralnet\n",
    "from lab_scripts.metrics.mp import mp_metrics\n",
    "from lab_scripts.utils import utils\n",
    "utils.change_directory_to_repo()\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "data = dataloader.load_data('mp/official/gex_to_adt')\n",
    "train_mod1 = data['train_mod1']\n",
    "train_mod2 = data['train_mod2']\n",
    "test_mod1 = data['test_mod1']\n",
    "test_mod2 = data['test_mod2']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "mod1 = utils.get_mod(train_mod1)\n",
    "mod2 = utils.get_mod(train_mod2)\n",
    "print(f'Modality of train_mod1 is {mod1}')\n",
    "print(f'Modality of train_mod2 is {mod2}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Modality of train_mod1 is gex\n",
      "Modality of train_mod2 is adt\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "task_type = utils.get_task_type(mod1, mod2)\n",
    "print(f'Current data type is {task_type}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Current data type is gex_to_adt\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Preprocess data\n",
    "# It will train StandardScaler for each modality\n",
    "train_mod1_X, scaler_mod1 = neuralnet.preprocess_dataset(train_mod1)\n",
    "train_mod2_X, scaler_mod2 = neuralnet.preprocess_dataset(train_mod2)\n",
    "train_dataloader = neuralnet.get_dataloader(\n",
    "    train_mod1_X, train_mod2_X, batch_size=128, shuffle=True\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# We've already trained scalers, so just pass them\n",
    "test_mod1_X, _ = neuralnet.preprocess_dataset(test_mod1, scaler_mod1)\n",
    "test_mod2_X, _ = neuralnet.preprocess_dataset(test_mod2, scaler_mod2)\n",
    "test_dataloader = neuralnet.get_dataloader(\n",
    "    test_mod1_X, test_mod2_X, batch_size=128, shuffle=False\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "config = {\n",
    "    # size of the input layer\n",
    "    'input_features': train_mod1_X.shape[1],\n",
    "\n",
    "    # size of the output layer\n",
    "    'output_features': train_mod2_X.shape[1],\n",
    "\n",
    "    # learning rate\n",
    "    'lr': 0.01,\n",
    "\n",
    "    'use_dropout': True,\n",
    "    'dropout': 0.5\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Create model\n",
    "model = neuralnet.BaselineModel(config)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Train it on gpu\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=50)\n",
    "trainer.fit(model, train_dataloader, test_dataloader)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type    | Params\n",
      "-------------------------------------\n",
      "0 | linear_1 | Linear  | 7.0 M \n",
      "1 | linear_2 | Linear  | 150 K \n",
      "2 | linear_3 | Linear  | 40.3 K\n",
      "3 | dropout  | Dropout | 0     \n",
      "-------------------------------------\n",
      "7.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.2 M     Total params\n",
      "28.671    Total estimated model params size (MB)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                                              "
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/simon/miniconda3/envs/nips/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/simon/miniconda3/envs/nips/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 15:  35%|███▍      | 82/236 [03:57<07:21,  2.87s/it, loss=0.592, v_num=0, val_loss=0.906]\n",
      "Epoch 49: 100%|██████████| 236/236 [00:05<00:00, 44.37it/s, loss=0.549, v_num=1, val_loss=0.865]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Make predictions\n",
    "predictions = trainer.predict(model, test_dataloader)\n",
    "\n",
    "# Concat them into single np.ndarray\n",
    "predictions = torch.cat(predictions, dim=0).cpu().numpy() "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/simon/miniconda3/envs/nips/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, predict dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predicting: 228it [00:00, ?it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Unscale predictions back to modality 2\n",
    "predictions = scaler_mod2.inverse_transform(predictions)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# Calculate target metric\n",
    "mp_metrics.calculate_target(predictions, test_mod2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.46105143"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('nips': conda)"
  },
  "interpreter": {
   "hash": "56a7e32d7961928a9f3e18e44fe070068f0318925842ce4245f771b32b697ac8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}